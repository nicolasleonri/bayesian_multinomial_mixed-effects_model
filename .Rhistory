# the random effect (1 | x) we are making it multinomial.
structure ~ distance + (1 | question) + (1 | participant),
data  = df,
family = multinomial(link=logit, refcat = NA),
# Number of available cores
cores = nc_cores,
iter = 1000, #standard: 2000. Reduce for faster processing.
warmup = 500, #standard: 1000. Reduce for faster processing.
# get all parameters and parameters classes to define priors automatically
prior = set_prior("normal(0, 2)", dpar = c("muelliptical", "mujuxtaposition", "muovertconnective")),
sample_prior = "yes",
thin = 5,
control = list(adapt_delta = 0.99),
# saves all information
save_pars = save_pars(group = TRUE, all = TRUE),
)
fit_multinomial_model = brm(
# Note: the brms package does a categorical model, but by adding
# the random effect (1 | x) we are making it multinomial.
structure ~ distance + (1 | question) + (1 | participant),
data  = df,
family = multinomial(link=logit),
# Number of available cores
cores = nc_cores,
iter = 1000, #standard: 2000. Reduce for faster processing.
warmup = 500, #standard: 1000. Reduce for faster processing.
# get all parameters and parameters classes to define priors automatically
prior = set_prior("normal(0, 2)", dpar = c("muelliptical", "mujuxtaposition", "muovertconnective")),
sample_prior = "yes",
thin = 5,
control = list(adapt_delta = 0.99),
# saves all information
save_pars = save_pars(group = TRUE, all = TRUE),
)
fit_multinomial_model = brm(
# Note: the brms package does a categorical model, but by adding
# the random effect (1 | x) we are making it multinomial.
structure ~ distance + (1 | question) + (1 | participant),
data  = df,
family = categorical(link=logit, refcat = NA),
# Number of available cores
cores = nc_cores,
iter = 1000, #standard: 2000. Reduce for faster processing.
warmup = 500, #standard: 1000. Reduce for faster processing.
# get all parameters and parameters classes to define priors automatically
prior = set_prior("normal(0, 2)", dpar = c("muelliptical", "mujuxtaposition", "muovertconnective")),
sample_prior = "yes",
thin = 5,
control = list(adapt_delta = 0.99),
# saves all information
save_pars = save_pars(group = TRUE, all = TRUE),
)
fit_multinomial_model = brm(
# Note: the brms package does a categorical model, but by adding
# the random effect (1 | x) we are making it multinomial.
structure ~ distance + (1 | question) + (1 | participant),
data  = df,
family = categorical(link=logit, refcat = NA),
# Number of available cores
cores = nc_cores,
iter = 100, #standard: 2000. Reduce for faster processing.
warmup = 10, #standard: 1000. Reduce for faster processing.
# get all parameters and parameters classes to define priors automatically
prior = set_prior("normal(0, 2)", dpar = c("muelliptical", "mujuxtaposition", "muovertconnective")),
sample_prior = "yes",
thin = 5,
control = list(adapt_delta = 0.99),
# saves all information
save_pars = save_pars(group = TRUE, all = TRUE),
)
conditional_effects(fit_multinomial_model, categorical = TRUE, plot = FALSE)
fit_multinomial_model = brm(
# Note: the brms package does a categorical model, but by adding
# the random effect (1 | x) we are making it multinomial.
structure ~ distance * overt_connective * elliptical * juxtaposition + (1 | question) + (1 | participant),
data  = df,
family = categorical(link=logit, refcat = NA),
# Number of available cores
cores = nc_cores,
iter = 100, #standard: 2000. Reduce for faster processing.
warmup = 10, #standard: 1000. Reduce for faster processing.
# get all parameters and parameters classes to define priors automatically
prior = set_prior("normal(0, 2)", dpar = c("muelliptical", "mujuxtaposition", "muovertconnective")),
sample_prior = "yes",
thin = 5,
control = list(adapt_delta = 0.99),
# saves all information
save_pars = save_pars(group = TRUE, all = TRUE),
)
# Then we get the categories we want to observe
target_values <- c(unique(df$structure))
# And we create binary columns of them if they were found or not
df$overt_connective <-
ifelse(df$structure %in% target_values[1], 1, 0)
df$elliptical <- ifelse(df$structure %in% target_values[2], 1, 0)
df$juxtaposition <- ifelse(df$structure %in% target_values[3], 1, 0)
# We factor them, as they're categorical values
df$overt_connective <- factor(df$overt_connective)
df$elliptical <- factor(df$elliptical)
df$juxtaposition <- factor(df$juxtaposition)
fit_multinomial_model = brm(
# Note: the brms package does a categorical model, but by adding
# the random effect (1 | x) we are making it multinomial.
structure ~ distance * overt_connective * elliptical * juxtaposition + (1 | question) + (1 | participant),
data  = df,
family = categorical(link=logit, refcat = NA),
# Number of available cores
cores = nc_cores,
iter = 100, #standard: 2000. Reduce for faster processing.
warmup = 10, #standard: 1000. Reduce for faster processing.
# get all parameters and parameters classes to define priors automatically
prior = set_prior("normal(0, 2)", dpar = c("muelliptical", "mujuxtaposition", "muovertconnective")),
sample_prior = "yes",
thin = 5,
control = list(adapt_delta = 0.99),
# saves all information
save_pars = save_pars(group = TRUE, all = TRUE),
)
fit_multinomial_model = brm(
# Note: the brms package does a categorical model, but by adding
# the random effect (1 | x) we are making it multinomial.
structure ~ distance * overt_connective * elliptical * juxtaposition + (1 | question) + (1 | participant),
data  = df,
family = categorical(link=logit, refcat = NA),
# Number of available cores
cores = nc_cores,
iter = 100, #standard: 2000. Reduce for faster processing.
warmup = 10, #standard: 1000. Reduce for faster processing.
# get all parameters and parameters classes to define priors automatically
prior = c(
set_prior("normal(0, 1)", dpar = "muelliptical"),
set_prior("normal(0, 2)", dpar = "mujuxtaposition"),
set_prior("normal(0, 3)", dpar = "muovertconnective")
),
sample_prior = "yes",
thin = 5,
control = list(adapt_delta = 0.99),
# saves all information
save_pars = save_pars(group = TRUE, all = TRUE),
)
conditional_effects(fit_multinomial_model, categorical = TRUE, plot = FALSE)
summary(fit_multinomial_model)
fit_multinomial_model = brm(
# Note: the brms package does a categorical model, but by adding
# the random effect (1 | x) we are making it multinomial.
structure ~ distance + (1 | question) + (1 | participant),
data  = df,
family = categorical(link=logit, refcat = NA),
# Number of available cores
cores = nc_cores,
iter = 100, #standard: 2000. Reduce for faster processing.
warmup = 10, #standard: 1000. Reduce for faster processing.
# get all parameters and parameters classes to define priors automatically
prior = c(
set_prior("normal(0, 1)", dpar = "muelliptical"),
set_prior("normal(0, 2)", dpar = "mujuxtaposition"),
set_prior("normal(0, 3)", dpar = "muovertconnective")
),
sample_prior = "yes",
thin = 5,
control = list(adapt_delta = 0.99),
# saves all information
save_pars = save_pars(group = TRUE, all = TRUE),
)
conditional_effects(fit_multinomial_model, categorical = TRUE, plot = FALSE)
summary(fit_multinomial_model)
# Model checking with posterior predictive checks
pp_check(fit_multinomial_model)
# Extract random effects into a nice table and saves it
results <- mixedup::extract_random_effects(fit_multinomial_model)
ce <- conditional_effects(fit_multinomial_model, categorical = TRUE)
ce <- as.data.frame(ce[[1]])
write.csv(ce, file = "results/results_conditional_effects.csv", row.names = FALSE)
# Visualize conditional effects
conditional_effects(fit_multinomial_model, categorical = TRUE, plot = FALSE)
# To get a table that includes the probability of each category, first we pivot the data
prob_table <- ce %>%
pivot_wider(
id_cols = c("distance", "cond__"),
names_from = "cats__",
values_from = "estimate__"
) %>%
select(-cond__) %>%
mutate(across(-c(distance), ~ifelse(is.na(.), 0, .)))  # Replace NAs with 0
# Rename the columns
colnames(prob_table) <- c("distance", "elliptical", "juxtaposition", "overt_connective")
# Saves it
write.csv(prob_table, file = "results/prob_table.csv", row.names = FALSE)
############ RESULTS AFTER LOGISTIC REGRESSION ###########
# ELLIPTICAL:
summary(lm(distance ~ elliptical, data = prob_table))
# P-value:
#Coefficient:
# JUXTAPOSITION:
summary(lm(distance ~ juxtaposition, data = prob_table))
# P-value:
#Coefficient:
# OVERT CONNECTIVE:
summary(lm(distance ~ overt_connective, data = prob_table))
# P-value:
#Coefficient:
prob_table
summary(lm(distance ~ juxtaposition, data = prob_table))
summary(lm(distance ~ overt_connective, data = prob_table))
############ CONFIGURATION ###########
library(readxl)
library(brms)
library(parallelly)
library(remotes)
# Package to deal with results (its not an official CRAN package yet. Needs package "remotes")
#remotes::install_github('m-clark/mixedup')
library(mixedup)
library(tidyr)
library(dplyr)
# Read and format data from Excel file
# Adjust the file path and sheet index as needed
df <- read_excel(
path = "data/distance.dataset.xlsx",
sheet = 1,
col_names = TRUE,
col_types = c("numeric", "text", "text", "numeric")
)
# Clean up the 'structure' column by removing line breaks
df$structure <- gsub("\\r\\n", "", df$structure)
# Extract numeric values from the 'question' column
df$question <- as.numeric(gsub("[^0-9]", "", df$question))
# Convert 'structure', 'question', and 'participant' columns to factors
df$structure <- factor(df$structure)
df$question <- factor(df$question)
df$participant <- factor(df$participant)
# Display a summary of the processed dataframe
summary(df)
# Then we get the categories we want to observe
target_values <- c(unique(df$structure))
# And we create binary columns of them if they were found or not
df$overt_connective <-
ifelse(df$structure %in% target_values[1], 1, 0)
df$elliptical <- ifelse(df$structure %in% target_values[2], 1, 0)
df$juxtaposition <- ifelse(df$structure %in% target_values[3], 1, 0)
# We factor them, as they're categorical values
df$overt_connective <- factor(df$overt_connective)
df$elliptical <- factor(df$elliptical)
df$juxtaposition <- factor(df$juxtaposition)
# And we observe them
summary(df)
# Fit a multinomial model using brms
fit_multinomial_model = brm(
# Note: the brms package does a categorical model, but by adding
# the random effect (1 | x) we are making it multinomial.
structure ~ distance + (1 | question) + (1 | participant),
data  = df,
family = categorical(link=logit, refcat = NA),
# Number of available cores
cores = nc_cores,
iter = 2000, #standard: 2000. Reduce for faster processing.
warmup = 1000, #standard: 1000. Reduce for faster processing.
prior = c(
set_prior("normal(0, 1)", dpar = "muelliptical"),
set_prior("normal(0, 2)", dpar = "mujuxtaposition"),
set_prior("normal(0, 3)", dpar = "muovertconnective")
),
sample_prior = "yes",
thin = 5,
control = list(adapt_delta = 0.99),
# saves all information
save_pars = save_pars(group = TRUE, all = TRUE),
)
nc_cores <- availableCores()
# Gets number of cores available in the machine
nc_cores <- availableCores()
# Fit a multinomial model using brms
fit_multinomial_model = brm(
# Note: the brms package does a categorical model, but by adding
# the random effect (1 | x) we are making it multinomial.
structure ~ distance + (1 | question) + (1 | participant),
data  = df,
family = categorical(link=logit, refcat = NA),
# Number of available cores
cores = nc_cores,
iter = 2000, #standard: 2000. Reduce for faster processing.
warmup = 1000, #standard: 1000. Reduce for faster processing.
prior = c(
set_prior("normal(0, 1)", dpar = "muelliptical"),
set_prior("normal(0, 2)", dpar = "mujuxtaposition"),
set_prior("normal(0, 3)", dpar = "muovertconnective")
),
sample_prior = "yes",
thin = 5,
control = list(adapt_delta = 0.99),
# saves all information
save_pars = save_pars(group = TRUE, all = TRUE),
)
conditional_effects(fit_multinomial_model, categorical = TRUE, plot = FALSE)
summary(fit_multinomial_model)
ranef(fit_multinomial_model)
pp_check(fit_multinomial_model)
pp_check(fit_multinomial_model, type = "xyz")
pp_check(fit, type = "error_hist", ndraws = 11)
pp_check(fit_multinomial_model, type = "error_hist", ndraws = 11)
pp_check(fit_multinomial_model, type = "xyz")
pp_check(fit_multinomial_model) # shows dens_overlay plot by default
results <- mixedup::extract_random_effects(fit_multinomial_model)
ce <- conditional_effects(fit_multinomial_model, categorical = TRUE)
ce <- as.data.frame(ce[[1]])
write.csv(ce, file = "results/results_conditional_effects.csv", row.names = FALSE)
results <- mixedup::extract_random_effects(fit_multinomial_model)
ce <- conditional_effects(fit_multinomial_model, categorical = TRUE)
ce <- as.data.frame(ce[[1]])
write.csv(ce, file = "results/results_conditional_effects.csv", row.names = FALSE)
conditional_effects(fit_multinomial_model, categorical = TRUE, plot = FALSE)
prob_table <- ce %>%
pivot_wider(
id_cols = c("distance", "cond__"),
names_from = "cats__",
values_from = "estimate__"
) %>%
select(-cond__) %>%
mutate(across(-c(distance), ~ifelse(is.na(.), 0, .)))  # Replace NAs with 0
# Rename the columns
colnames(prob_table) <- c("distance", "elliptical", "juxtaposition", "overt_connective")
# Saves it
write.csv(prob_table, file = "results/prob_table.csv", row.names = FALSE)
# ELLIPTICAL:
summary(lm(distance ~ elliptical, data = prob_table))
# P-value:
#Coefficient:
# JUXTAPOSITION:
summary(lm(distance ~ juxtaposition, data = prob_table))
# P-value:
#Coefficient:
summary(lm(distance ~ elliptical, data = prob_table))
summary(lm(distance ~ juxtaposition, data = prob_table))
summary(lm(distance ~ overt_connective, data = prob_table))
summary(lm(distance ~ elliptical, data = prob_table))
plot(distance, elliptical, data = prob_table)
?plot
plot(prob_table$distance, prob_table$elliptical)
summary(lm(distance ~ elliptical, data = prob_table))
plot(prob_table$distance, prob_table$elliptical)
lm_model <- lm(prob_table$distance ~ prob_table$elliptical)
abline(lm_model, col = "blue")# P-value: < 2e-16
#Coefficient: -409.710
summary(lm(distance ~ elliptical, data = prob_table))
plot(prob_table$distance, prob_table$elliptical)
lm_model <- lm(prob_table$distance ~ prob_table$elliptical - 1)
abline(lm_model, col = "blue")# P-value: < 2e-16
#Coefficient: -409.710
prob_table$distance
prob_table$elliptical
lm(prob_table$distance ~ prob_table$elliptical - 1)
summary(lm(distance ~ elliptical, data = prob_table))
summary(lm(elliptical ~ distance, data = prob_table))
plot(prob_table$distance, prob_table$elliptical)
lm_model <- lm(prob_table$elliptical ~ prob_table$distance - 1)
summary(lm(elliptical ~ distance, data = prob_table))
plot(prob_table$distance, prob_table$elliptical)
lm_model <- lm(prob_table$elliptical ~ prob_table$distance)
abline(lm_model, col = "blue")
summary(lm(elliptical ~ distance, data = prob_table))
plot(prob_table$distance, prob_table$elliptical)
lm_model <- lm(prob_table$elliptical ~ prob_table$distance-1)
abline(lm_model, col = "blue")
summary(lm(elliptical ~ distance, data = prob_table))
plot(prob_table$distance, prob_table$elliptical)
lm_model <- lm(prob_table$elliptical ~ prob_table$distance)
abline(lm_model, col = "blue")
distance
prob_table
prob_table[2]
prob_table[1]
prob_table[2:]
prob_table[2:4]
prob_table[2:4] <- prob_table[2:4]*100
prob_table[2:4]
# To get a table that includes the probability of each category, first we pivot the data
prob_table <- ce %>%
pivot_wider(
id_cols = c("distance", "cond__"),
names_from = "cats__",
values_from = "estimate__"
) %>%
select(-cond__) %>%
mutate(across(-c(distance), ~ifelse(is.na(.), 0, .)))  # Replace NAs with 0
# Rename the columns
colnames(prob_table) <- c("distance", "elliptical", "juxtaposition", "overt_connective")
prob_table
write.csv(prob_table, file = "results/prob_table.csv", row.names = FALSE)
prob_table
summary(lm(elliptical ~ distance, data = prob_table))
plot(prob_table$distance, prob_table$elliptical)
plot(prob_table$distance, prob_table$elliptical, y=0:1)
plot(prob_table$distance, prob_table$elliptical, y=0:1)
plot(prob_table$distance, prob_table$elliptical, ylim=c(0,1))
lm_model <- lm(prob_table$elliptical ~ prob_table$distance)
abline(lm_model, col = "blue")
summary(lm(elliptical ~ distance, data = prob_table))
summary(lm(juxtaposition ~ distance, data = prob_table))
plot(prob_table$distance, prob_table$juxtaposition, ylim=c(0,1))
lm_model <- lm(prob_table$juxtaposition ~ prob_table$distance)
abline(lm_model, col = "blue")
# P-value: < 5.20e-12
#Coefficient: -0.0007504
summary(lm(elliptical ~ distance, data = prob_table))
plot(prob_table$distance, prob_table$elliptical, ylim=c(0,1))
lm_model <- lm(prob_table$elliptical ~ prob_table$distance)
abline(lm_model, col = "blue")
# P-value: < 5.20e-12
#Coefficient: -0.0007504
summary(lm(juxtaposition ~ distance, data = prob_table))
plot(prob_table$distance, prob_table$juxtaposition, ylim=c(0,1))
lm_model <- lm(prob_table$juxtaposition ~ prob_table$distance)
abline(lm_model, col = "blue")
# P-value: < <2e-16
#Coefficient: -4.410e-04
summary(lm(overt_connective ~ distance, data = prob_table))
plot(prob_table$distance, prob_table$overt_connective, ylim=c(0,1))
lm_model <- lm(prob_table$overt_connective ~ prob_table$distance)
abline(lm_model, col = "blue")
# P-value: < <2e-16
#Coefficient: -4.410e-04
summary(lm(juxtaposition ~ distance, data = prob_table))
plot(prob_table$distance, prob_table$juxtaposition, ylim=c(0,1))
lm_model <- lm(prob_table$juxtaposition ~ prob_table$distance)
abline(lm_model, col = "blue")
# P-value: < 2e-16
#Coefficient: -0.0004410
summary(lm(elliptical ~ distance, data = prob_table))
plot(prob_table$distance, prob_table$elliptical, ylim=c(0,1))
lm_model <- lm(prob_table$elliptical ~ prob_table$distance)
abline(lm_model, col = "blue")
# P-value: < 2.16e-09
#Coefficient: -0.0007504
summary(lm(juxtaposition ~ distance, data = prob_table))
plot(prob_table$distance, prob_table$juxtaposition, ylim=c(0,1))
lm_model <- lm(prob_table$juxtaposition ~ prob_table$distance)
abline(lm_model, col = "blue")
# OVERT CONNECTIVE:
summary(lm(overt_connective ~ distance, data = prob_table))
plot(prob_table$distance, prob_table$overt_connective, ylim=c(0,1))
lm_model <- lm(prob_table$overt_connective ~ prob_table$distance)
abline(lm_model, col = "blue")
# P-value: <2e-16
#Coefficient: 0.0012242
# ELLIPTICAL:
summary(lm(elliptical ~ distance, data = prob_table))
plot(prob_table$distance, prob_table$elliptical, ylim=c(0,1))
lm_model <- lm(prob_table$elliptical ~ prob_table$distance)
abline(lm_model, col = "blue")
# P-value: < 2.16e-09
#Coefficient: -0.0007504
# JUXTAPOSITION:
summary(lm(juxtaposition ~ distance, data = prob_table))
plot(prob_table$distance, prob_table$juxtaposition, ylim=c(0,1))
lm_model <- lm(prob_table$juxtaposition ~ prob_table$distance)
abline(lm_model, col = "blue")
# P-value: < 2e-16
#Coefficient: -0.0004410
# OVERT CONNECTIVE:
summary(lm(overt_connective ~ distance, data = prob_table))
plot(prob_table$distance, prob_table$overt_connective, ylim=c(0,1))
lm_model <- lm(prob_table$overt_connective ~ prob_table$distance)
abline(lm_model, col = "blue")
# P-value: <2e-16
#Coefficient: 0.0012242
ls
q()
summary(lm(overt_connective ~ distance, data = prob_table))
plot(prob_table$distance, prob_table$overt_connective, ylim=c(0,1))
lm_model <- lm(prob_table$overt_connective ~ prob_table$distance)
abline(lm_model, col = "blue")
# P-value: <2e-16
#Coefficient: 0.0012242
summary(lm(juxtaposition ~ distance, data = prob_table))
plot(prob_table$distance, prob_table$juxtaposition, ylim=c(0,1))
lm_model <- lm(prob_table$juxtaposition ~ prob_table$distance)
abline(lm_model, col = "blue")
# P-value: < 2e-16
#Coefficient: -0.0004410
summary(fit_multinomial_model)
ranef(fit_multinomial_model)
############ CONFIGURATION ###########
library(readxl)
library(brms)
library(parallelly)
library(remotes)
# Package to deal with results ( not an official CRAN package yet. Needs package "remotes")
#remotes::install_github('m-clark/mixedup')
library(mixedup)
library(tidyr)
library(dplyr)
ranef(fit_multinomial_model)
posterior_summary(fit_multinomial_model)
plot(posterior_summary(fit_multinomial_model))
x <- seq(-1, 1, length=100)
y <- dunif(x, min = 0, max =1)
plot(x,y, type = 'l')
x <- seq(-1, 3, length=100)
y <- dunif(x, min = 0, max =1)
plot(x,y, type = 'l')
x <- seq(-1, 5, length=100)
y <- dunif(x, min = 0, max =1)
plot(x,y, type = 'l')
x <- seq(-1, 5, length=100)
y <- dunif(x, min = 0, max =2)
plot(x,y, type = 'l')
x <- seq(-1, 5, length=100)
y <- dunif(x, min = 0, max =3)
plot(x,y, type = 'l')
summary(fit_multinomial_model)
x <- seq(-1, 5, length=100)
y <- dunif(x, min = 0, max =3)
plot(x,y, type = 'l')
